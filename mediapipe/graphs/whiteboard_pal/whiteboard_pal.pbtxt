
# MediaPipe graph that performs hands tracking on desktop with TensorFlow
# Lite on CPU.
# Used in the example in
# mediapipe/examples/desktop/hand_tracking:hand_tracking_cpu.

# CPU image. (ImageFrame)
input_stream: "input_video"
input_stream: "input_key"

# CPU image. (ImageFrame)
output_stream: "output_video"

profiler_config {
  trace_enabled: true
  enable_profiler: true
  trace_log_interval_count: 200
  trace_log_path: "./logs/"
}

# Generates side packet cotaining max number of hands to detect/track.
node {
  calculator: "ConstantSidePacketCalculator"
  output_side_packet: "PACKET:num_hands"
  node_options: {
    [type.googleapis.com/mediapipe.ConstantSidePacketCalculatorOptions]: {
      packet { int_value: 1 }
    }
  }
}

node {
    calculator: "ConstantSidePacketCalculator"
    output_side_packet: "PACKET:0:frame_width"
    output_side_packet: "PACKET:1:frame_height"
    node_options: {
      [type.googleapis.com/mediapipe.ConstantSidePacketCalculatorOptions]: {
        packet { int_value: 640 }
        packet { int_value: 480 }
      }
    }
}

node {
  calculator: "FlowLimiterCalculator"
  input_stream: "input_video"
  input_stream: "FINISHED:landmarks"
  input_stream_info: {
    tag_index: "FINISHED"
    back_edge: true
  }
  output_stream: "throttled_input_video"
}

# Detects/tracks hand landmarks.
node {
  calculator: "HandLandmarkTrackingCpu"
  input_stream: "IMAGE:throttled_input_video"
  input_side_packet: "NUM_HANDS:num_hands"
  output_stream: "LANDMARKS:landmarks"
}

# Subgraph that renders annotations and overlays them on top of the input
# images (see hand_renderer_cpu.pbtxt).
node {
  calculator: "WhiteboardPalGestureDetectionCalculator"
  input_stream: "LANDMARKS:landmarks"
  # input_stream: "HANDEDNESS:handedness" don't care about handedness rn
  output_stream: "DRAW_COORDS:finger_coords"
  output_stream: "HAS_GESTURE:has_gesture"
}

node {
    calculator: "WhiteboardPalCanvasCalculator"
    input_stream: "DRAW_COORDS:finger_coords"
    input_stream: "HAS_GESTURE:has_gesture"
    input_stream: "SUBSTRATE:throttled_input_video"
    input_stream: "KEY:input_key"
    input_side_packet: "FRAME_WIDTH:frame_width"
    input_side_packet: "FRAME_HEIGHT:frame_height"
    output_stream: "DRAWN_FRAME:output_video"
}
